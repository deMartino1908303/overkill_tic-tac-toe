{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0d1f01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import equinox as eqx\n",
    "import jax.random as jr\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tic_tac import TicTacToe\n",
    "key = jr.key(420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "1d51761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Model(eqx.Module):\n",
    "    # Layers\n",
    "    embedd: eqx.nn.Linear\n",
    "\n",
    "    Q1: eqx.nn.Linear\n",
    "    K1: eqx.nn.Linear\n",
    "    V1: eqx.nn.Linear\n",
    "\n",
    "    Q2: eqx.nn.Linear\n",
    "    K2: eqx.nn.Linear\n",
    "    V2: eqx.nn.Linear\n",
    "\n",
    "    post_att: eqx.nn.Linear\n",
    "    aggregator: eqx.nn.Linear\n",
    "\n",
    "    classifier1: eqx.nn.Linear\n",
    "    classifier2: eqx.nn.Linear\n",
    "\n",
    "    att_1_norm: eqx.nn.LayerNorm\n",
    "    att_2_norm: eqx.nn.LayerNorm\n",
    "    norm: eqx.nn.LayerNorm\n",
    "\n",
    "    drop_1: eqx.nn.Dropout\n",
    "    drop_2: eqx.nn.Dropout\n",
    "    drop: eqx.nn.Dropout\n",
    "\n",
    "    def __init__(self, key):\n",
    "        keys = jr.split(key, 16)\n",
    "\n",
    "        self.embedd = eqx.nn.Linear(9, 256, use_bias=False, key=keys[0])\n",
    "\n",
    "        self.Q1 = eqx.nn.Linear(256, 256, key=keys[1])\n",
    "        self.K1 = eqx.nn.Linear(256, 256, key=keys[2])\n",
    "        self.V1 = eqx.nn.Linear(256, 256, key=keys[3])\n",
    "\n",
    "        self.Q2 = eqx.nn.Linear(256, 256, key=keys[4])\n",
    "        self.K2 = eqx.nn.Linear(256, 256, key=keys[5])\n",
    "        self.V2 = eqx.nn.Linear(256, 256, key=keys[6])\n",
    "\n",
    "        self.post_att = eqx.nn.Linear(256, 256, key=keys[7])\n",
    "        self.aggregator = eqx.nn.Linear(512, 1, use_bias=False, key=keys[8])\n",
    "\n",
    "        self.classifier1 = eqx.nn.Linear(512, 128, key=keys[9])\n",
    "        self.classifier2 = eqx.nn.Linear(128, 9, use_bias=False, key=keys[10])\n",
    "\n",
    "        self.att_1_norm = eqx.nn.LayerNorm(256)\n",
    "        self.att_2_norm = eqx.nn.LayerNorm(256)\n",
    "        self.norm = eqx.nn.LayerNorm(512)\n",
    "\n",
    "        self.drop_1 = eqx.nn.Dropout(0.2)\n",
    "        self.drop_2 = eqx.nn.Dropout(0.2)\n",
    "        self.drop = eqx.nn.Dropout(0.4)\n",
    "\n",
    "    def __call__(self, inputs, *, key, training=False, KV_K = False):\n",
    "\n",
    "        k1, k2, k3 = jr.split(key, 3)\n",
    "\n",
    "        inputs = jnp.array(inputs)\n",
    "\n",
    "        # ---- Embedding ----\n",
    "        inp = jax.vmap(jax.vmap(self.embedd, in_axes=0), in_axes=0)(inputs)   # (b, 6, 9)\n",
    "        \n",
    "        seq_len = inputs.shape[1]\n",
    "\n",
    "        # ---- Causal mask ----\n",
    "        if training :\n",
    "            mask = jnp.tril(jnp.ones((seq_len, seq_len)))\n",
    "            mask = (1.0 - mask) * -1e9\n",
    "            mask = jnp.expand_dims(mask, axis=0)\n",
    "        else :\n",
    "            mask = jnp.zeros((seq_len, seq_len))\n",
    "\n",
    "        # ---- KVQ ----\n",
    "        Q1 = jax.vmap(jax.vmap(self.Q1))(inp)\n",
    "        K1 = jax.vmap(jax.vmap(self.K1))(inp)\n",
    "        V1 = jax.vmap(jax.vmap(self.V1))(inp)\n",
    "\n",
    "        Q2 = jax.vmap(jax.vmap(self.Q2))(inp)\n",
    "        K2 = jax.vmap(jax.vmap(self.K2))(inp)\n",
    "        V2 = jax.vmap(jax.vmap(self.V2))(inp)\n",
    "        \n",
    "        # ---- Scaled Dot-Product ----\n",
    "        scores_1 = jnp.matmul(Q1, jnp.swapaxes(K1, -1, -2)) / jnp.sqrt(256.0)\n",
    "        scores_2 = jnp.matmul(Q2, jnp.swapaxes(K2, -1, -2)) / jnp.sqrt(256.0)\n",
    "\n",
    "        # ---- Add mask ----\n",
    "        scores_1 = scores_1 + mask\n",
    "        scores_2 = scores_2 + mask\n",
    "\n",
    "        # ---- Softmax + Dropout ----\n",
    "        attn_weights_1 = self.drop_1(\n",
    "            jax.nn.softmax(scores_1),\n",
    "            key=k1,\n",
    "            inference=not training\n",
    "        )\n",
    "        context_1 = jnp.matmul(attn_weights_1, V1)\n",
    "\n",
    "        attn_weights_2 = self.drop_2(\n",
    "            jax.nn.softmax(scores_2),\n",
    "            key=k2,\n",
    "            inference=not training\n",
    "        )\n",
    "        context_2 = jnp.matmul(attn_weights_2, V2)\n",
    "\n",
    "        # ---- Residual + Norm ----\n",
    "        att_1 = jax.vmap(jax.vmap(self.att_1_norm))(context_1 + inp)\n",
    "        att_2 = jax.vmap(jax.vmap(self.att_2_norm))(context_2 + inp)\n",
    "\n",
    "        # ---- Gated merge ----\n",
    "        gate_input = jnp.concatenate([att_1, att_2], axis=-1)\n",
    "        \n",
    "        lamb = jax.nn.sigmoid(jax.vmap(jax.vmap(self.aggregator))(gate_input))\n",
    "\n",
    "        att = lamb * att_1 + (1 - lamb) * att_2\n",
    "\n",
    "        # ---- Post attention ----\n",
    "        fin_att = jax.vmap(jax.vmap(self.post_att))(att)\n",
    "\n",
    "        pooled = jnp.mean(fin_att, axis=1)\n",
    "        last_token = fin_att[:, -1, :]\n",
    "        concatenated = jnp.concatenate([pooled, last_token], axis=-1)\n",
    "\n",
    "        concatenated = self.drop(\n",
    "            concatenated,\n",
    "            key=k3,\n",
    "            inference=not training\n",
    "        )\n",
    "\n",
    "        att_out = jax.vmap(self.norm)(concatenated)\n",
    "\n",
    "        x = jax.vmap(self.classifier1)(att_out)\n",
    "        x = jax.nn.relu(x)\n",
    "        x = jax.vmap(self.classifier2)(x)\n",
    "\n",
    "        if KV_K:\n",
    "            return {\"res\" : x, \"att1\" : att_1, \"att2\" : att_2}\n",
    "\n",
    "        return {\"res\" : x}\n",
    "\n",
    "\n",
    "key = jr.key(420)\n",
    "k, key = jr.split(key, 2)\n",
    "model = Model(key= k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dee8cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "def load_game_dict(filename=\"move_dict.json\"):\n",
    "    with open(filename, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # convert string keys back to tuples\n",
    "    restored_dict = {}\n",
    "    for ii, tmp in enumerate(data.items()):\n",
    "        key, value = tmp\n",
    "        restored_dict[ii] = ast.literal_eval(key), value\n",
    "\n",
    "    return restored_dict\n",
    "\n",
    "df = pd.DataFrame(load_game_dict()).T\n",
    "df.columns = (\"state\", \"best\")\n",
    "df = df[(df[\"best\"].apply(lambda x : None not in x ))]\n",
    "\n",
    "\n",
    "def one_hot_vec(inp, key):\n",
    "\n",
    "    inp = jnp.array(inp)\n",
    "    n = jnp.round((1/len(inp)), 4)\n",
    "    res = jnp.zeros(9)\n",
    "    res = res.at[inp].set(n)\n",
    "    layer = jr.randint(key, (1), 0 ,6)\n",
    "    out = jnp.zeros((6,9))\n",
    "    out = out.at[layer,].set(res)\n",
    "    return layer, out\n",
    "\n",
    "def board_fixer(inp, memory):\n",
    "\n",
    "    inp = jnp.array(inp)\n",
    "    out = jnp.zeros((6,9))\n",
    "    out = out.at[memory,].set(inp)\n",
    "    return out\n",
    "\n",
    "target = []\n",
    "memory = []\n",
    "for ii in df[\"best\"]:\n",
    "    k, key = jr.split(key)\n",
    "    remember, to_append = one_hot_vec(ii, k)\n",
    "    memory.append(remember)\n",
    "    target.append(to_append)\n",
    "\n",
    "target = jnp.array(target)\n",
    "\n",
    "\n",
    "board_fixed = []\n",
    "for board, ii in zip(df[\"state\"], memory):\n",
    "    board_fixed.append(board_fixer(board, ii))\n",
    "\n",
    "board_fixed = jnp.array(board_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6cd8820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.5 0.  0.5]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0. ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1., -1.,  1., -1.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(target[4,])\n",
    "board_fixed[4,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9a0262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "396.22"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22adb975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0. , 0. , 0. , 0. , 0.5, 0.5, 0. , 0. , 0. ], dtype=float32)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def CE_loss(y_preds, y_true):\n",
    "    delta = 1e-9\n",
    "    return -jnp.sum(y_true*jnp.log(y_preds+delta))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
